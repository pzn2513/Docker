services:
  php:
    hostname: php
    # build:
    #   context: ./Dockerfiles/php
    #   dockerfile: php.dockerfile
    image: ghini/php-think-swoole
    environment:
      - TZ=Asia/Shanghai
    volumes:
      - ./wwwroot:/wwwroot
      - ./etc/php/php.ini:/usr/local/etc/php/php.ini
    networks:
      - backend
    
  nginx:
    hostname: nginx
    image: nginx
    environment:
      - TZ=Asia/Shanghai
    ports:
      - 80:80
      - 443:443
    volumes:
      - ./wwwroot:/wwwroot
      - ./etc/nginx/ssl:/etc/nginx/ssl
      - ./etc/nginx/conf.d:/etc/nginx/conf.d
    networks:
      - backend
    
  mysql:
    hostname: mysql
    image: mysql
    environment:
      - TZ=Asia/Shanghai
      - MYSQL_ROOT_PASSWORD=root_password
      - MYSQL_DATABASE=mydb
      - MYSQL_USER=myuser
      - MYSQL_PASSWORD=mypassword
    volumes:
      - mysql_data:/var/lib/mysql
    ports:
      - 3306:3306
    networks:
      - backend

  redis:
    hostname: redis
    image: redis
    environment:
      - TZ=Asia/Shanghai
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    networks:
      - backend
    command: ["redis-server", "--appendonly", "yes", "--appendfsync", "everysec"] # AOF操作持久化
    # command: ["redis-server", "--save", "900 1", "--save", "300 10", "--save", "60 10000"] # RDB快照持久化

  clickhouse:
    hostname: clickhouse
    image: clickhouse/clickhouse-server
    environment:
      - TZ=Asia/Shanghai
    ports:
      - 8123:8123
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      - ./etc/clickhouse/users.xml:/etc/clickhouse-server/users.xml
    networks:
      - backend

  elasticsearch:
    hostname: elasticsearch
    image: docker.elastic.co/elasticsearch/elasticsearch:${ES_VERSION}
    environment:
      - TZ=Asia/Shanghai
      - discovery.type=single-node
      - ELASTIC_PASSWORD=changeme
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
    networks:
      - backend
    volumes:
      - esdata:/usr/share/elasticsearch/data
      - ./etc/elasticsearch/plugins:/usr/share/elasticsearch/plugins
  kibana:
    hostname: kibana
    image: docker.elastic.co/kibana/kibana:${ES_VERSION}
    environment:
      - TZ=Asia/Shanghai
      - ELASTICSEARCH_USERNAME=kibana_system
      - ELASTICSEARCH_PASSWORD=changeme
    volumes:
      - ./etc/kibana/kibana.yml:/usr/share/kibana/config/kibana.yml
    ports:
      - "5601:5601"
    networks:
      - backend
  filebeat:
    hostname: filebeat
    image: docker.elastic.co/beats/filebeat:${ES_VERSION}
    environment:
      - TZ=Asia/Shanghai
    user: root
    command: ["filebeat", "-e", "--strict.perms=false"]
    volumes:
      - ./etc/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    depends_on:
      - elasticsearch
    networks:
      - backend
  logstash:
    hostname: logstash
    image: docker.elastic.co/logstash/logstash:${ES_VERSION}
    environment:
      - TZ=Asia/Shanghai
    volumes:
      - ./etc/logstash/logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    ports:
      - "5044:5044"
    networks:
      - backend
    depends_on:
      - elasticsearch

  # kafka:
  #   image: wurstmeister/kafka
  #   ports:
  #     - "9092:9092"
  #   environment:
  #     KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
  #     KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
  #     KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
  #   # volumes:
  #   #   - ./etc/kafka:/etc/kafka # 挂载自定义的 kafka 配置
  #   depends_on:
  #     - zookeeper
  #   networks:
  #     - backend

  # zookeeper:
  #   image: wurstmeister/zookeeper
  #   ports:
  #     - "2181:2181"
  #   networks:
  #     - backend

  # rabbitmq:
  #   image: rabbitmq:management
  #   ports:
  #     - "5672:5672"
  #     - "15672:15672"
  #   networks:
  #     - backend

networks:
  backend:
  frontend:

volumes:
  mysql_data:
  clickhouse_data:
  redis_data:
  esdata: